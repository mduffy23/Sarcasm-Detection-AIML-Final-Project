{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/mduffy23/Sarcasm-Detection-AIML-Final-Project/blob/main/Sarcasm_Detection_Final_Project_AIML.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "720e89cf",
      "metadata": {
        "id": "720e89cf"
      },
      "source": [
        "# Final Project - Sarcasm Detection"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "There is a common experience amoung people of reading a text and not being sure if it is supposed to be sarcastic or not (or even being on the reverse, trying to text and make sure the other person knows you are being sarcastic). It is a bit awkward and difficult to interpret without inflection that one usually uses when saying something sarcastic.\n",
        "\n",
        "This project aims to generate a model that can predict of a statement is sarcastic or not, purely based on the text used. Capitalization, punctuation, and word choice can all help indicate whether or not the writer of a comment meant to express the statement sarcastically.\n",
        "\n",
        "- The baseline model if TFID.\n",
        "- The final model is a fine tuned RoBERTA model."
      ],
      "metadata": {
        "id": "GahyZwqP5Lxh"
      },
      "id": "GahyZwqP5Lxh"
    },
    {
      "cell_type": "markdown",
      "id": "94d2c0e8",
      "metadata": {
        "id": "94d2c0e8"
      },
      "source": [
        "## Imports"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "--E5huwtaU58",
      "metadata": {
        "id": "--E5huwtaU58"
      },
      "outputs": [],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "project_path = '/content/drive/MyDrive/Final AIML Project - Sarcasm Detection'"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#!pip install -q transformers datasets accelerate sentencepiece\n",
        "#!pip install -q torch --index-url https://download.pytorch.org/whl/cu121\n",
        "#!pip install optuna"
      ],
      "metadata": {
        "id": "vkH1sbt98hXH"
      },
      "id": "vkH1sbt98hXH",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "26760a5c",
      "metadata": {
        "id": "26760a5c"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import re\n",
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.feature_extraction.text import CountVectorizer\n",
        "from wordcloud import WordCloud\n",
        "from scipy.sparse import hstack\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from tqdm.notebook import tqdm\n",
        "from datasets import Dataset, ClassLabel, Features\n",
        "from sklearn.metrics import classification_report, confusion_matrix\n",
        "from transformers import BertTokenizer, BertForSequenceClassification\n",
        "from transformers import TrainingArguments, Trainer\n",
        "import nltk\n",
        "from nltk.stem import WordNetLemmatizer\n",
        "from nltk.tokenize import word_tokenize\n",
        "nltk.download('punkt')\n",
        "nltk.download('punkt_tab')\n",
        "nltk.download('wordnet')\n",
        "nltk.download('omw-1.4')\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "from datasets import Dataset\n",
        "from transformers import (\n",
        "    RobertaTokenizerFast,\n",
        "    RobertaModel,\n",
        "    TrainingArguments,\n",
        "    Trainer,\n",
        "    default_data_collator\n",
        ")\n",
        "from transformers.modeling_outputs import SequenceClassifierOutput\n",
        "from sklearn.metrics import f1_score, accuracy_score, precision_recall_fscore_support, confusion_matrix\n",
        "import optuna"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "1617c189",
      "metadata": {
        "id": "1617c189"
      },
      "source": [
        "## Dataset"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Dataset comes from https://www.kaggle.com/datasets/danofer/sarcasm. The dataset was downloaded via kaggle hub on my local machine and moved into google drive for easy access. This dataset contains 1,010,826 comments from Reddit, balanced between not sarcastic and sarcastic comments. The sarcasm data was generated by scraping comments containing a sarcasm tag.\n",
        "\n",
        "I initally planned to use a headline sarcasm dataset, but this was insufficient because the *sarcastic* comments did not relfect the sarcasm used by people in conversation. The idea behind this project is that one could get a text out of no where (or in the midst of chat) and get a reasonable prediction of the text they are reading is sarcastic or not. Reddit was a far better alternative to capture sarcasm that people utilzie."
      ],
      "metadata": {
        "id": "-YNmCRYNwIsX"
      },
      "id": "-YNmCRYNwIsX"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "1b96f3d0",
      "metadata": {
        "id": "1b96f3d0"
      },
      "outputs": [],
      "source": [
        "sarcasm = pd.read_csv(project_path + '/train-balanced-sarcasm.csv')\n",
        "print(sarcasm.info())\n",
        "display(sarcasm.head())\n",
        "display(pd.DataFrame(sarcasm['label'].value_counts().reset_index().rename(columns={'index': 'label', 'label': 'count'})))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "Wz1USRlASqc5",
      "metadata": {
        "id": "Wz1USRlASqc5"
      },
      "outputs": [],
      "source": [
        "display(sarcasm.isna().sum())\n",
        "sarcasm.dropna(inplace=True)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Must drop any null comments."
      ],
      "metadata": {
        "id": "7omE8j6f3iGX"
      },
      "id": "7omE8j6f3iGX"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "C-8AVLKKwTkH",
      "metadata": {
        "id": "C-8AVLKKwTkH"
      },
      "outputs": [],
      "source": [
        "sarcasm['subreddit'].value_counts().head(20)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "There are many different *subreddits* that are specific to particular topics. The most common is a very generic subreddit called \"AskReddit\" which is followed by more specific domains like politics and worldnews.\n",
        "\n",
        "One important consideration for this project is the lack of context the model gets. The \"AskReddit\" subreddit poses questions that are answered by people. Sometimes the answers are sarcastic, but one would only know that based on the question at hand. Perhaps putting in a feature for parent comment would help with the association of more contextual sarcasm, but I want to focus more on catching sarcasm that comes out of the blue. Not using any parent comment for context should help the model understand the essence of sarcasm, rather than how to respond to someone sarcastically. Maybe a sarcasm generation model would be better suited to use a parent comment for a training feature."
      ],
      "metadata": {
        "id": "mjwvV0B13lEd"
      },
      "id": "mjwvV0B13lEd"
    },
    {
      "cell_type": "markdown",
      "source": [
        "Taking a fairly large sample of the data and then splitting it into X and y."
      ],
      "metadata": {
        "id": "Yw5qKDqi7sMB"
      },
      "id": "Yw5qKDqi7sMB"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "IjKK4X_skfQm",
      "metadata": {
        "id": "IjKK4X_skfQm"
      },
      "outputs": [],
      "source": [
        "sample_sarcasm, _ = train_test_split(sarcasm, train_size=0.75, random_state=102, stratify=sarcasm['label'])\n",
        "sample_sarcasm.reset_index(drop=True, inplace=True)\n",
        "sample_sarcasm.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "6Rhqq7q9jGKM",
      "metadata": {
        "id": "6Rhqq7q9jGKM"
      },
      "outputs": [],
      "source": [
        "X = sample_sarcasm['comment']\n",
        "y = sample_sarcasm['label']\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.20, random_state=102, stratify=y)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Text Processing"
      ],
      "metadata": {
        "id": "VbU7gx_1NyMa"
      },
      "id": "VbU7gx_1NyMa"
    },
    {
      "cell_type": "markdown",
      "id": "qq38meeInmJ_",
      "metadata": {
        "id": "qq38meeInmJ_"
      },
      "source": [
        "### Sarcasm Indications"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "I want the model to learn sarcasm from training on the Reddit comments, but I also want to help it along by identifying common indicators of sarcasm. I created function to add a lexical sarcasm feature to any string of text. This will be used as a secondary variable in both the baseline and final models."
      ],
      "metadata": {
        "id": "zxG_KQz4-f2s"
      },
      "id": "zxG_KQz4-f2s"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "TAi8-HdwpE-y",
      "metadata": {
        "id": "TAi8-HdwpE-y"
      },
      "outputs": [],
      "source": [
        "intensifiers = {'literally', 'totally', 'completely', 'absolutely', 'seriously', 'really', 'just' 'sooo', 'wooow'}\n",
        "irony = {'yeah right', 'oh great', 'just perfect', 'of course', 'sure thing', 'oh yeah', 'oh,'}\n",
        "sarcasm_punctuation = {'!', '!!', '!?', '?!'}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "WbSplCXbn0zw",
      "metadata": {
        "id": "WbSplCXbn0zw"
      },
      "outputs": [],
      "source": [
        "def count_elongated(token):\n",
        "    return 1 if re.search(r\"(.)\\1\\1+\", token) else 0\n",
        "\n",
        "def lexical_features_one(text):\n",
        "    text_lower = text.lower()\n",
        "    tokens = re.findall(r'\\w+|\\S', text)\n",
        "\n",
        "    intensifier_count = sum(t.lower() in intensifiers for t in tokens)\n",
        "\n",
        "    irony_present = 1 if any(phrase in text_lower for phrase in irony) else 0\n",
        "\n",
        "    punctuation_count = sum(text.count(p) for p in sarcasm_punctuation)\n",
        "\n",
        "    cap_tokens = sum(1 for t in tokens if len(t) > 2 and t.isupper())\n",
        "    cap_ratio = cap_tokens / max(len(tokens), 1)\n",
        "\n",
        "    elongated_count = sum(count_elongated(t) for t in tokens)\n",
        "\n",
        "    return [\n",
        "        intensifier_count,\n",
        "        irony_present,\n",
        "        punctuation_count,\n",
        "        cap_ratio,\n",
        "        elongated_count\n",
        "    ]\n",
        "\n",
        "def build_lexical_matrix(text_list):\n",
        "    return np.vstack([lexical_features_one(t) for t in text_list])"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "sZVabq22wAbj",
      "metadata": {
        "id": "sZVabq22wAbj"
      },
      "source": [
        "### Lemmatizer"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "This is for TFID, not RoBerta. A transformer model like RoBerta..."
      ],
      "metadata": {
        "id": "NYiVDup-74Rn"
      },
      "id": "NYiVDup-74Rn"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "Q2HwCicxwC4t",
      "metadata": {
        "id": "Q2HwCicxwC4t"
      },
      "outputs": [],
      "source": [
        "# Lemmatize functions\n",
        "\n",
        "## For Modelling\n",
        "def sarcasm_lemma_tokenizer(text):\n",
        "  lemmatizer = WordNetLemmatizer()\n",
        "  text = text.lower()\n",
        "  tokens = word_tokenize(text)\n",
        "  lemmas = [lemmatizer.lemmatize(tok) if tok.isalpha() else tok for tok in tokens]\n",
        "  return lemmas\n",
        "\n",
        "## For visuals\n",
        "def sarcasm_lemma_vectorizer_no_punc(text):\n",
        "  tokens = sarcasm_lemma_tokenizer(text)\n",
        "  return [tok.lower() for tok in tokens if tok.isalpha() and tok not in sarcasm_punctuation]\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "8d1ccf87",
      "metadata": {
        "id": "8d1ccf87"
      },
      "source": [
        "## Data Exploration"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "MtQmslWi8IrD",
      "metadata": {
        "id": "MtQmslWi8IrD"
      },
      "outputs": [],
      "source": [
        "def plot_top_grams(df, label_val, n_gram_range = (1, 2), top=20):\n",
        "  df_label = df[df['label'] == label_val]['comment']\n",
        "  vectorizer = CountVectorizer(tokenizer=sarcasm_lemma_vectorizer_no_punc, token_pattern=None, lowercase=True, ngram_range=n_gram_range, stop_words='english')\n",
        "  X = vectorizer.fit_transform(df_label)\n",
        "\n",
        "  counts = np.asarray(X.sum(axis=0)).flatten()\n",
        "  vocab = vectorizer.get_feature_names_out()\n",
        "\n",
        "  freq_df = pd.DataFrame({'ngram': vocab, 'count': counts})\n",
        "  freq_df = freq_df.sort_values(by='count', ascending=False).head(top)\n",
        "\n",
        "  plt.figure(figsize=(12, 8))\n",
        "  bars = plt.barh(freq_df['ngram'], freq_df['count'], color='blue', alpha = 0.7)\n",
        "  plt.gca().invert_yaxis() # Show highest frequency on top\n",
        "  plt.xticks(fontsize=12)\n",
        "  plt.yticks(fontsize=12)\n",
        "  plt.xlabel('Count', fontsize=14)\n",
        "  plt.ylabel('N-gram', fontsize=18)\n",
        "  plt.title(f'Top {top} {n_gram_range}-grams for {'Sarcastic' if label_val == 1 else 'Non-sarcastic'} Comments', fontsize=18)\n",
        "\n",
        "  # Add data labels\n",
        "  for bar in bars:\n",
        "      plt.text(bar.get_width(), bar.get_y() + bar.get_height()/2, f' {int(bar.get_width())}', va='center')\n",
        "\n",
        "  plt.tight_layout()\n",
        "  sns.despine()\n",
        "  plt.show()\n",
        "\n",
        "plot_top_grams(sample_sarcasm, 1)\n",
        "plot_top_grams(sample_sarcasm, 0)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "8589c357",
      "metadata": {
        "id": "8589c357"
      },
      "source": [
        "## Baseline TF-IDF"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Define a train test split\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.20, random_state=102, stratify=y)"
      ],
      "metadata": {
        "id": "nWj81jw48L1N"
      },
      "id": "nWj81jw48L1N",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "b41c9237",
      "metadata": {
        "id": "b41c9237"
      },
      "outputs": [],
      "source": [
        "# TF-IDF vectorization\n",
        "vectorizer = TfidfVectorizer(tokenizer=sarcasm_lemma_tokenizer, ngram_range=(1, 2), min_df=2, preprocessor=None, token_pattern=None)\n",
        "X_train_vec = vectorizer.fit_transform(X_train)\n",
        "X_test_vec = vectorizer.transform(X_test)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "FqlN1FoDw6BK",
      "metadata": {
        "id": "FqlN1FoDw6BK"
      },
      "outputs": [],
      "source": [
        "# Add lexical features\n",
        "X_train_lex = build_lexical_matrix(X_train)\n",
        "X_test_lex = build_lexical_matrix(X_test)\n",
        "\n",
        "# Add to dataset\n",
        "X_train = hstack([X_train_vec, X_train_lex])\n",
        "X_test = hstack([X_test_vec, X_test_lex])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "fe2d57d9",
      "metadata": {
        "id": "fe2d57d9"
      },
      "outputs": [],
      "source": [
        "# Linear classifier\n",
        "clf = LogisticRegression(max_iter=500, class_weight = 'balanced')\n",
        "clf.fit(X_train, y_train)\n",
        "\n",
        "# Evaluation\n",
        "y_pred = clf.predict(X_test)\n",
        "print(classification_report(y_test, y_pred))\n",
        "print(confusion_matrix(y_test, y_pred))"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Simple logisitic regression does a nice job on generally learning sarcasm (significantly better than guessing)."
      ],
      "metadata": {
        "id": "rVckLnPU_OS7"
      },
      "id": "rVckLnPU_OS7"
    },
    {
      "cell_type": "markdown",
      "id": "26302d71",
      "metadata": {
        "id": "26302d71"
      },
      "source": [
        "## BERT"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "05f874b0",
      "metadata": {
        "id": "05f874b0"
      },
      "outputs": [],
      "source": [
        "dataset = Dataset.from_dict({\"text\": X, \"label\": y})\n",
        "features = Features({\"text\": dataset.features[\"text\"], \"label\": ClassLabel(num_classes=2, names=[0, 1])})\n",
        "dataset = dataset.cast(features)\n",
        "dataset = dataset.train_test_split(test_size=0.20, seed=102, stratify_by_column='label')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "cbb6e666",
      "metadata": {
        "id": "cbb6e666"
      },
      "outputs": [],
      "source": [
        "tokenizer = BertTokenizer.from_pretrained(\"bert-base-cased\")\n",
        "\n",
        "model = BertForSequenceClassification.from_pretrained(\"bert-base-cased\", num_labels=2)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "7378330c",
      "metadata": {
        "id": "7378330c"
      },
      "outputs": [],
      "source": [
        "def tokenize(batch):\n",
        "    return tokenizer(batch[\"text\"], padding=\"max_length\", truncation=True)\n",
        "\n",
        "def add_lexical_features(batch):\n",
        "    features = [lexical_features_one(text) for text in batch['text']]\n",
        "    batch['lexical_features'] = features\n",
        "    return batch\n",
        "\n",
        "tokenized = dataset.map(tokenize, batched=True)\n",
        "tokenized = tokenized.map(add_lexical_features, batched=True)\n",
        "tokenized = tokenized.remove_columns([\"text\"])\n",
        "tokenized = tokenized.rename_column(\"label\", \"labels\")\n",
        "tokenized.set_format(\"torch\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "e9107cf8",
      "metadata": {
        "id": "e9107cf8"
      },
      "outputs": [],
      "source": [
        "training_args = TrainingArguments(\n",
        "    output_dir= project_path + \"/test\",\n",
        "    eval_strategy=\"epoch\",\n",
        "    save_strategy=\"epoch\",\n",
        "    learning_rate=0.001,\n",
        "    per_device_train_batch_size=16,\n",
        "    per_device_eval_batch_size=16,\n",
        "    num_train_epochs=3,\n",
        "    weight_decay=0.01,\n",
        "    report_to=\"none\"\n",
        ")\n",
        "\n",
        "trainer = Trainer(\n",
        "    model=model,\n",
        "    args=training_args,\n",
        "    train_dataset=tokenized[\"train\"],\n",
        "    eval_dataset=tokenized[\"test\"]\n",
        ")\n",
        "\n",
        "trainer.train()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "M4AoTfLM-U4y",
      "metadata": {
        "id": "M4AoTfLM-U4y"
      },
      "outputs": [],
      "source": [
        "trainer.evaluate()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "lBtGlYOhbdCm",
      "metadata": {
        "id": "lBtGlYOhbdCm"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "model.to(device)\n",
        "model.eval()\n",
        "\n",
        "sentences = ['Great work, no one has ever thought of that.']\n",
        "\n",
        "inputs = tokenizer(sentences, padding=True, truncation=True, return_tensors=\"pt\")\n",
        "inputs = {k: v.to(device) for k, v in inputs.items()}\n",
        "\n",
        "with torch.no_grad():\n",
        "  outputs = model(**inputs)\n",
        "  logits = outputs.logits\n",
        "\n",
        "probs = torch.softmax(logits, dim=1)\n",
        "preds = torch.argmax(probs, dim=1)\n",
        "\n",
        "print(probs)\n",
        "print(preds)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "8LcY1Nyae5xL",
      "metadata": {
        "id": "8LcY1Nyae5xL"
      },
      "outputs": [],
      "source": [
        "outputs = trainer.predict(tokenized[\"test\"])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "Q95kvm-De6Mk",
      "metadata": {
        "id": "Q95kvm-De6Mk"
      },
      "outputs": [],
      "source": [
        "outputs = trainer.predict(tokenized[\"test\"])\n",
        "logits = outputs.predictions\n",
        "labels = outputs.label_ids\n",
        "preds = np.argmax(logits, axis=1)\n",
        "print(classification_report(labels, preds))\n",
        "print(confusion_matrix(labels, preds))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "URgIh4rYY1nG",
      "metadata": {
        "id": "URgIh4rYY1nG"
      },
      "outputs": [],
      "source": [
        "model.save_pretrained(project_path + '/withsarcasmref')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "hFidt1T-Zl-r",
      "metadata": {
        "id": "hFidt1T-Zl-r"
      },
      "outputs": [],
      "source": [
        "tokenizer.save_pretrained(project_path + '/withsarcasmref')"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import RobertaTokenizerFast\n",
        "\n",
        "tokenizer = RobertaTokenizerFast.from_pretrained(\"roberta-base\")"
      ],
      "metadata": {
        "id": "Gu8E__ZvRGfC"
      },
      "id": "Gu8E__ZvRGfC",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def tokenize(batch):\n",
        "    return tokenizer(\n",
        "        batch[\"text\"],\n",
        "        padding=\"max_length\",\n",
        "        truncation=True,\n",
        "        return_tensors=None\n",
        "    )\n",
        "\n",
        "def add_lexical_features(batch):\n",
        "    batch[\"lexical_features\"] = [\n",
        "        lexical_features_one(text) for text in batch[\"text\"]\n",
        "    ]\n",
        "    return batch\n",
        "\n",
        "# cast labels\n",
        "features = Features({\n",
        "    \"text\": dataset.features[\"text\"],\n",
        "    \"label\": ClassLabel(num_classes=2),\n",
        "})\n",
        "dataset = dataset.cast(features)\n",
        "\n",
        "# train-test split\n",
        "dataset = dataset.train_test_split(\n",
        "    test_size=0.20,\n",
        "    seed=102,\n",
        "    stratify_by_column=\"label\"\n",
        ")\n",
        "\n",
        "# Apply tokenizer + lexical features\n",
        "tokenized = dataset.map(tokenize, batched=True)\n",
        "tokenized = tokenized.map(add_lexical_features, batched=True)\n",
        "\n",
        "# remove unused columns\n",
        "tokenized = tokenized.remove_columns([\"text\"])\n",
        "tokenized = tokenized.rename_column(\"label\", \"labels\")\n",
        "\n",
        "# Convert everything to PyTorch tensors\n",
        "tokenized.set_format(\"torch\")"
      ],
      "metadata": {
        "id": "_vvSGUQLRVzO"
      },
      "id": "_vvSGUQLRVzO",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "from transformers import RobertaModel, RobertaConfig\n",
        "\n",
        "class RobertaWithFeatures(nn.Module):\n",
        "    def __init__(self, feature_dim, num_labels=2):\n",
        "        super().__init__()\n",
        "        self.roberta = RobertaModel.from_pretrained(\"roberta-base\")\n",
        "        self.dropout = nn.Dropout(0.1)\n",
        "\n",
        "        # The CLS embedding is 768-dimensional for roberta-base\n",
        "        roberta_dim = self.roberta.config.hidden_size\n",
        "\n",
        "        # Combine CLS + custom feature vector\n",
        "        combined_dim = roberta_dim + feature_dim\n",
        "\n",
        "        self.classifier = nn.Sequential(\n",
        "            nn.Linear(combined_dim, 256),\n",
        "            nn.ReLU(),\n",
        "            nn.Dropout(0.1),\n",
        "            nn.Linear(256, num_labels)\n",
        "        )\n",
        "\n",
        "    def forward(self, input_ids, attention_mask, features):\n",
        "        # RoBERTa forward\n",
        "        outputs = self.roberta(\n",
        "            input_ids=input_ids,\n",
        "            attention_mask=attention_mask\n",
        "        )\n",
        "\n",
        "        cls_emb = outputs.last_hidden_state[:, 0, :]  # CLS token\n",
        "\n",
        "        # Concatenate CLS with custom lexical features\n",
        "        combined = torch.cat([cls_emb, features], dim=1)\n",
        "        logits = self.classifier(combined)\n",
        "        return logits\n",
        "\n",
        "model = RobertaWithFeatures(feature_dim=5)\n",
        "\n",
        "class SarcasmDataset(torch.utils.data.Dataset):\n",
        "    def __init__(self, encodings, features, labels):\n",
        "        self.encodings = encodings\n",
        "        self.features = torch.tensor(features, dtype=torch.float)\n",
        "        self.labels = torch.tensor(labels)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n",
        "        item[\"features\"] = self.features[idx]\n",
        "        item[\"labels\"] = self.labels[idx]\n",
        "        return item\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.labels)"
      ],
      "metadata": {
        "id": "FI6_ATr4NVer"
      },
      "id": "FI6_ATr4NVer",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import Trainer\n",
        "import torch.nn as nn\n",
        "\n",
        "class CustomTrainer(Trainer):\n",
        "    def compute_loss(self, model, inputs, return_outputs=False):\n",
        "        labels = inputs[\"labels\"]\n",
        "        lexical_features = inputs[\"lexical_features\"]\n",
        "\n",
        "        outputs = model(\n",
        "            input_ids=inputs[\"input_ids\"],\n",
        "            attention_mask=inputs[\"attention_mask\"],\n",
        "            lexical_features=lexical_features\n",
        "        )\n",
        "\n",
        "        loss_fct = nn.CrossEntropyLoss()\n",
        "        loss = loss_fct(outputs, labels)\n",
        "\n",
        "        return (loss, outputs) if return_outputs else loss"
      ],
      "metadata": {
        "id": "6oovSeW2SAxM"
      },
      "id": "6oovSeW2SAxM",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import Trainer\n",
        "\n",
        "class CustomTrainer(Trainer):\n",
        "    def compute_loss(self, model, inputs, return_outputs=False):\n",
        "        labels = inputs.pop(\"labels\")\n",
        "        features = inputs.pop(\"features\")\n",
        "        outputs = model(**inputs, features=features)\n",
        "        loss_fn = nn.CrossEntropyLoss()\n",
        "        loss = loss_fn(outputs, labels)\n",
        "        return (loss, outputs) if return_outputs else loss"
      ],
      "metadata": {
        "id": "2zxDj9B8Ne_N"
      },
      "id": "2zxDj9B8Ne_N",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "training_args = TrainingArguments(\n",
        "    output_dir= project_path + \"/results\",\n",
        "    per_device_train_batch_size=16,\n",
        "    per_device_eval_batch_size=16,\n",
        "    num_train_epochs=3,\n",
        "    evaluation_strategy=\"epoch\",\n",
        "    logging_strategy=\"epoch\",\n",
        ")\n",
        "\n",
        "trainer = CustomTrainer(\n",
        "    model=model,\n",
        "    args=training_args,\n",
        "    train_dataset=tokenized[\"train\"],\n",
        "    eval_dataset=tokenized[\"test\"],\n",
        ")\n",
        "\n",
        "trainer.train()"
      ],
      "metadata": {
        "id": "S2t4uC0CNiH-"
      },
      "id": "S2t4uC0CNiH-",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##RoBERTa"
      ],
      "metadata": {
        "id": "LB8sS_dhT85p"
      },
      "id": "LB8sS_dhT85p"
    },
    {
      "cell_type": "code",
      "source": [
        "# Utilize GPU well\n",
        "torch.backends.cuda.matmul.allow_tf32 = True\n",
        "torch.backends.cudnn.benchmark = True\n",
        "torch.set_float32_matmul_precision(\"medium\")"
      ],
      "metadata": {
        "id": "ps3M2VrVsa6e"
      },
      "id": "ps3M2VrVsa6e",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Model defintion with Lexical Features\n",
        "class RobertaWithLexical(nn.Module):\n",
        "    def __init__(self, model_name=\"roberta-base\", feature_dim=5, num_labels=2, dropout=0.1):\n",
        "        super().__init__()\n",
        "        self.roberta = RobertaModel.from_pretrained(model_name)\n",
        "        hidden_size = self.roberta.config.hidden_size\n",
        "\n",
        "        self.dropout = nn.Dropout(dropout)\n",
        "        self.classifier = nn.Linear(hidden_size + feature_dim, num_labels)\n",
        "\n",
        "    def forward(self, input_ids=None, attention_mask=None, lexical_features=None, labels=None, **kwargs):\n",
        "        # Roberta embeddings\n",
        "        outputs = self.roberta(input_ids=input_ids, attention_mask=attention_mask, return_dict=True)\n",
        "\n",
        "        cls_emb = outputs.last_hidden_state[:, 0, :]  # CLS token\n",
        "\n",
        "        # Lexical features\n",
        "        if lexical_features is None:\n",
        "            lexical_features = torch.zeros(cls_emb.size(0), 0, device=cls_emb.device, dtype=cls_emb.dtype)\n",
        "        else:\n",
        "            lexical_features = lexical_features.to(cls_emb.device)\n",
        "            if lexical_features.dtype != cls_emb.dtype:\n",
        "                lexical_features = lexical_features.to(dtype=cls_emb.dtype)\n",
        "\n",
        "        # Concatenate\n",
        "        combined = torch.cat([cls_emb, lexical_features], dim=1)\n",
        "        pooled = self.dropout(combined)\n",
        "        logits = self.classifier(pooled)\n",
        "\n",
        "        # Compute loss if labels provided\n",
        "        loss = None\n",
        "        if labels is not None:\n",
        "            loss_fct = nn.CrossEntropyLoss()\n",
        "            loss = loss_fct(logits.view(-1, logits.size(-1)), labels.view(-1))\n",
        "\n",
        "        # Return proper HF output\n",
        "        return SequenceClassifierOutput(loss=loss, logits=logits)"
      ],
      "metadata": {
        "id": "ylSUtn1DsWHH"
      },
      "id": "ylSUtn1DsWHH",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Lexical feature generation\n",
        "intensifiers = {\"literally\", \"absolutely\", \"totally\", \"completely\", \"seriously\"}\n",
        "irony = {\"yeah right\", \"sure\", \"as if\", \"i bet\", \"no way\", \"oh great\", \"oh yeah\"}\n",
        "sarcasm_punctuation = {\"!\",\"!!\",\"!?\",\"?!\"}\n",
        "\n",
        "def count_elongated(token):\n",
        "    return 1 if re.search(r\"(.)\\1\\1+\", token) else 0\n",
        "\n",
        "def lexical_features_one(text):\n",
        "    text = str(text)\n",
        "    text_lower = text.lower()\n",
        "    tokens = re.findall(r'\\w+|\\S', text)\n",
        "\n",
        "    intensifier_count = sum(t.lower() in intensifiers for t in tokens)\n",
        "    irony_present = 1 if any(phrase in text_lower for phrase in irony) else 0\n",
        "    punctuation_count = sum(text.count(p) for p in sarcasm_punctuation)\n",
        "    cap_tokens = sum(1 for t in tokens if len(t) > 2 and t.isupper())\n",
        "    cap_ratio = cap_tokens / max(len(tokens), 1)\n",
        "    elongated_count = sum(count_elongated(t) for t in tokens)\n",
        "\n",
        "    return [intensifier_count, irony_present, punctuation_count, cap_ratio, elongated_count]"
      ],
      "metadata": {
        "id": "qWfk6hpOsqSx"
      },
      "id": "qWfk6hpOsqSx",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Data set up\n",
        "MODEL_NAME = \"roberta-base\"\n",
        "tokenizer = RobertaTokenizerFast.from_pretrained(MODEL_NAME)\n",
        "\n",
        "X = sample_sarcasm['comment'].tolist()\n",
        "y = sample_sarcasm['label'].tolist()\n",
        "\n",
        "def add_lexical(batch):\n",
        "    batch[\"lexical_features\"] = [np.array(lexical_features_one(x), dtype=np.float32) for x in batch[\"text\"]]\n",
        "    return batch\n",
        "\n",
        "def tokenize(batch):\n",
        "    return tokenizer(batch[\"text\"], truncation=True, padding=\"max_length\", max_length=128)\n",
        "\n",
        "dataset = Dataset.from_dict({\"text\": X, \"labels\": y})\n",
        "dataset = dataset.train_test_split(test_size=0.2, seed=102)\n",
        "\n",
        "dataset = dataset.map(add_lexical, batched=True)\n",
        "dataset = dataset.map(tokenize, batched=True)\n",
        "dataset = dataset.remove_columns([\"text\"])\n",
        "dataset.set_format(type=\"torch\", columns=[\"input_ids\", \"attention_mask\", \"lexical_features\", \"labels\"])"
      ],
      "metadata": {
        "id": "ckyAKWMctUST"
      },
      "id": "ckyAKWMctUST",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "We used a train test split here since we are using a lot of data to train. Training loops (even using Colab Pro GPUs) can take 20-30 minutes for one model. Using cross validation would multiply that 5x, which is just too exspensive and time consuming for the resources available."
      ],
      "metadata": {
        "id": "aD0YkpfK8sRr"
      },
      "id": "aD0YkpfK8sRr"
    },
    {
      "cell_type": "code",
      "source": [
        "# Training helpers\n",
        "\n",
        "## Freeze\n",
        "def freeze_roberta(model, train_last_n=4):\n",
        "    total = model.roberta.config.num_hidden_layers\n",
        "    train_from = total - train_last_n\n",
        "\n",
        "    for name, param in model.roberta.named_parameters():\n",
        "        match = re.search(r\"encoder\\.layer\\.(\\d+)\\.\", name)\n",
        "        if match:\n",
        "            layer = int(match.group(1))\n",
        "            if layer < train_from:\n",
        "                param.requires_grad = False\n",
        "        elif \"embeddings\" in name:\n",
        "            param.requires_grad = False\n",
        "\n",
        "## Training Metrics\n",
        "def metrics(p):\n",
        "    preds = np.argmax(p.predictions, axis=1)\n",
        "    return {\n",
        "        \"accuracy\": accuracy_score(p.label_ids, preds),\n",
        "        \"f1\": f1_score(p.label_ids, preds)\n",
        "    }"
      ],
      "metadata": {
        "id": "ZQb3O11SwBrY"
      },
      "id": "ZQb3O11SwBrY",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Training helpers\n",
        "\n",
        "# Freeze\n",
        "def freeze_roberta(model, train_last_n=4):\n",
        "    total = model.roberta.config.num_hidden_layers\n",
        "    train_from = total - train_last_n\n",
        "\n",
        "    for name, param in model.roberta.named_parameters():\n",
        "        match = re.search(r\"encoder\\.layer\\.(\\d+)\\.\", name)\n",
        "        if match:\n",
        "            layer = int(match.group(1))\n",
        "            if layer < train_from:\n",
        "                param.requires_grad = False\n",
        "        elif \"embeddings\" in name:\n",
        "            param.requires_grad = False\n",
        "\n",
        "class CustomTrainer(Trainer):\n",
        "    def compute_loss(self, model, inputs, return_outputs=False, **kwargs):\n",
        "        labels = inputs.pop(\"labels\")\n",
        "        lexical = inputs.pop(\"lexical_features\")\n",
        "\n",
        "        outputs = model(\n",
        "            **inputs,\n",
        "            lexical_features=lexical,\n",
        "            labels=labels,\n",
        "            **kwargs\n",
        "        )\n",
        "\n",
        "        loss = outputs.loss\n",
        "\n",
        "        return (loss, outputs) if return_outputs else loss\n",
        "\n",
        "def metrics(p):\n",
        "    preds = np.argmax(p.predictions, axis=1)\n",
        "    return {\n",
        "        \"accuracy\": accuracy_score(p.label_ids, preds),\n",
        "        \"f1\": f1_score(p.label_ids, preds)\n",
        "    }\n",
        "\n",
        "#Good\n",
        "# ==============================================================\n",
        "# 6. TRAINING\n",
        "# ==============================================================\n",
        "\n",
        "model = RobertaWithLexical()\n",
        "freeze_roberta(model, train_last_n=4)\n",
        "\n",
        "# Try compile()\n",
        "try:\n",
        "    model = torch.compile(model)\n",
        "    print(\"Compiled model for faster training.\")\n",
        "except Exception as e:\n",
        "    print(\"torch.compile failed:\", e)\n",
        "\n",
        "#training_args = TrainingArguments(\n",
        "#    output_dir=\"/content/drive/MyDrive/Final AIML Project - Sarcasm Detection/RobertaLarge\",\n",
        "#    per_device_train_batch_size=32,\n",
        "#    per_device_eval_batch_size=64,\n",
        "#    eval_strategy=\"epoch\",\n",
        "#    save_strategy=\"epoch\",\n",
        "#    remove_unused_columns=False,\n",
        "#    fp16=True,\n",
        "#    optim=\"adamw_torch_fused\",\n",
        "#    learning_rate=3e-5,\n",
        "#    num_train_epochs=3,\n",
        "#    dataloader_num_workers=4,\n",
        "#    dataloader_pin_memory=True,\n",
        "#    dataloader_persistent_workers=True,\n",
        "#    report_to=\"none\"\n",
        "#)\n",
        "\n",
        "#trainer = Trainer(\n",
        "#    model=model,\n",
        "#    args=training_args,\n",
        "#    train_dataset=dataset[\"train\"],\n",
        "#    eval_dataset=dataset[\"test\"],\n",
        "#    tokenizer=tokenizer,\n",
        "#    data_collator=default_data_collator,\n",
        "#    compute_metrics=metrics,\n",
        "#)\n",
        "\n",
        "\n",
        "#trainer.train()\n",
        "#trainer.save_model(\"/content/drive/MyDrive/Final AIML Project - Sarcasm Detection/RobertaLarge\")"
      ],
      "metadata": {
        "id": "ROWLsi-ITdcN"
      },
      "id": "ROWLsi-ITdcN",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Optuna Helpers\n",
        "def optuna_hp_space(trial):\n",
        "    return {\n",
        "        \"learning_rate\": trial.suggest_float(\"learning_rate\", 1e-6, 6e-5, log=True),\n",
        "        \"weight_decay\": trial.suggest_float(\"weight_decay\", 0.0, 0.2),\n",
        "        \"warmup_ratio\": trial.suggest_float(\"warmup_ratio\", 0.0, 0.2)\n",
        "    }\n",
        "\n",
        "def model_init(trial=None):\n",
        "    dropout = 0.1\n",
        "    train_last_n = 4\n",
        "\n",
        "    # If Optuna trial is active, override the defaults\n",
        "    if trial is not None:\n",
        "        dropout = trial.suggest_float(\"classifier_dropout\", 0.05, 0.4)\n",
        "        train_last_n = trial.suggest_int(\"train_last_n\", 1, 6)\n",
        "\n",
        "    model = RobertaWithLexical(dropout=dropout)\n",
        "\n",
        "    freeze_roberta(model, train_last_n=train_last_n)\n",
        "\n",
        "    return model"
      ],
      "metadata": {
        "id": "pFmKXdFKvjCU"
      },
      "id": "pFmKXdFKvjCU",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Hyperparameter tuning - Ran for over an hour\n",
        "training_args = TrainingArguments(\n",
        "    output_dir=\"optuna_roberta_fast\",\n",
        "    per_device_train_batch_size=32,\n",
        "    per_device_eval_batch_size=64,\n",
        "    num_train_epochs=1,\n",
        "    warmup_ratio=0.0,        # overwritten by optuna\n",
        "    learning_rate=2e-5,      # overwritten by optuna\n",
        "    weight_decay=0.0,        # overwritten\n",
        "    eval_strategy=\"epoch\",\n",
        "    save_strategy=\"no\",\n",
        "    logging_strategy=\"no\",\n",
        "    fp16=True,\n",
        "    optim=\"adamw_torch_fused\",\n",
        "    report_to=\"none\",\n",
        ")\n",
        "\n",
        "trainer = Trainer(\n",
        "    model_init=model_init,\n",
        "    args=training_args,\n",
        "    train_dataset=dataset[\"train\"],\n",
        "    eval_dataset=dataset[\"test\"],\n",
        "    tokenizer=tokenizer,\n",
        "    data_collator=default_data_collator,\n",
        "    compute_metrics=metrics,\n",
        ")\n",
        "\n",
        "study = optuna.create_study(\n",
        "    direction=\"maximize\",\n",
        "    pruner=optuna.pruners.MedianPruner(n_warmup_steps=0)\n",
        ")\n",
        "\n",
        "best_trial = trainer.hyperparameter_search(\n",
        "    n_trials=10,                     # fast\n",
        "    hp_space=optuna_hp_space,\n",
        "    backend=\"optuna\",\n",
        "    direction=\"maximize\",\n",
        "    compute_objective=lambda m: m[\"eval_f1\"],   # F1 target\n",
        ")\n",
        "\n",
        "print(best_trial)"
      ],
      "metadata": {
        "id": "FUIpNl3maXqX"
      },
      "id": "FUIpNl3maXqX",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "besthyperparameters={'learning_rate': 2.485002246616929e-05, 'weight_decay': 0.1802756018668522, 'warmup_ratio': 0.018819509939976123, 'classifier_dropout': 0.16749163342760462, 'train_last_n': 4}"
      ],
      "metadata": {
        "id": "e9B-SnfJ_wMM"
      },
      "id": "e9B-SnfJ_wMM",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def compute_metrics(eval_pred):\n",
        "    logits, labels = eval_pred.predictions, eval_pred.label_ids\n",
        "\n",
        "    # argmax over classes\n",
        "    preds = np.argmax(logits, axis=1)\n",
        "\n",
        "    precision, recall, f1, _ = precision_recall_fscore_support(\n",
        "        labels, preds, average=\"weighted\"\n",
        "    )\n",
        "\n",
        "    acc = accuracy_score(labels, preds)\n",
        "\n",
        "    return {\n",
        "        \"accuracy\": acc,\n",
        "        \"precision\": precision,\n",
        "        \"recall\": recall,\n",
        "        \"f1\": f1\n",
        "    }"
      ],
      "metadata": {
        "id": "3JCGL1DKxTIz"
      },
      "id": "3JCGL1DKxTIz",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "dataset"
      ],
      "metadata": {
        "id": "0CM8DDBNS7Ai"
      },
      "id": "0CM8DDBNS7Ai",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Utilize best parameters\n",
        "best = besthyperparameters # best_trial.hyperparameters\n",
        "model = RobertaWithLexical(dropout=best[\"classifier_dropout\"])\n",
        "freeze_roberta(model, train_last_n=best[\"train_last_n\"])\n",
        "\n",
        "# Try to compile for speed\n",
        "try:\n",
        "    model = torch.compile(model)\n",
        "    print(\"Compiled model for faster training.\")\n",
        "except Exception as e:\n",
        "    print(\"torch.compile failed:\", e)\n",
        "\n",
        "training_args = TrainingArguments(\n",
        "    output_dir=\"/content/drive/MyDrive/Final AIML Project - Sarcasm Detection/HypertunedRoBerta/training\",\n",
        "    per_device_train_batch_size=32,\n",
        "    per_device_eval_batch_size=64,\n",
        "    eval_strategy=\"epoch\",\n",
        "    save_strategy=\"epoch\",\n",
        "    remove_unused_columns=False,\n",
        "    fp16=True,\n",
        "    optim=\"adamw_torch_fused\",\n",
        "    learning_rate=best[\"learning_rate\"],\n",
        "    warmup_ratio=best[\"warmup_ratio\"],\n",
        "    weight_decay=best[\"weight_decay\"],\n",
        "    num_train_epochs=3,\n",
        "    dataloader_num_workers=4,\n",
        "    dataloader_pin_memory=True,\n",
        "    dataloader_persistent_workers=True,\n",
        "    report_to=\"none\",\n",
        ")\n",
        "\n",
        "trainer = Trainer(\n",
        "    model=model,\n",
        "    args=training_args,\n",
        "    train_dataset=dataset[\"train\"],\n",
        "    eval_dataset=dataset[\"test\"],\n",
        "    tokenizer=tokenizer,\n",
        "    data_collator=default_data_collator,\n",
        "    compute_metrics=compute_metrics,\n",
        ")\n",
        "\n",
        "trainer.train()\n",
        "trainer.save_model(\"/content/drive/MyDrive/Final AIML Project - Sarcasm Detection/HypertunedRoBerta/saved\")"
      ],
      "metadata": {
        "id": "8CuZMhTWE_ys"
      },
      "id": "8CuZMhTWE_ys",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "preds_output = trainer.predict(dataset[\"test\"])\n",
        "\n",
        "logits = preds_output.predictions[1]        # shape: (num_samples, 2)\n",
        "preds = np.argmax(logits, axis=1)           # predicted classes: 0 or 1\n",
        "labels = dataset[\"test\"][\"labels\"]          # Get true labels directly from the dataset\n",
        "\n",
        "from sklearn.metrics import accuracy_score, f1_score, confusion_matrix\n",
        "\n",
        "print(\"Accuracy:\", accuracy_score(labels, preds))\n",
        "print(\"F1:\", f1_score(labels, preds))\n",
        "print(\"Confusion matrix:\\n\", confusion_matrix(labels, preds))\n",
        "print(classification_report(labels, preds))"
      ],
      "metadata": {
        "id": "H4KJqQH82kcw"
      },
      "id": "H4KJqQH82kcw",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def predict_sarcasm(model, text, tokenizer=tokenizer, device=None):\n",
        "    model.eval()\n",
        "    device = device or (\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "    model.to(device)\n",
        "\n",
        "    if isinstance(text, str):\n",
        "        texts = [text]\n",
        "    else:\n",
        "        texts = text\n",
        "\n",
        "    # Tokenize\n",
        "    encodings = tokenizer(texts, truncation=True, padding=\"max_length\", max_length=128, return_tensors=\"pt\")\n",
        "\n",
        "    # Lexical features\n",
        "    lexical_features = torch.tensor([lexical_features_one(t) for t in texts], dtype=torch.float32)\n",
        "\n",
        "    # Move to device\n",
        "    input_ids = encodings[\"input_ids\"].to(device)\n",
        "    attention_mask = encodings[\"attention_mask\"].to(device)\n",
        "    lexical_features = lexical_features.to(device)\n",
        "\n",
        "    with torch.no_grad():\n",
        "        outputs = model(input_ids=input_ids,\n",
        "                        attention_mask=attention_mask,\n",
        "                        lexical_features=lexical_features)\n",
        "        logits = outputs.logits\n",
        "        probs = torch.softmax(logits, dim=1).cpu().numpy()\n",
        "        preds = np.argmax(probs, axis=1)\n",
        "\n",
        "    # Return single prediction if input was a string\n",
        "    if isinstance(text, str):\n",
        "        return {\"predicted_label\": int(preds[0]), \"probabilities\": probs[0]}\n",
        "    else:\n",
        "        return [{\"predicted_label\": int(p), \"probabilities\": prob} for p, prob in zip(preds, probs)]\n",
        "\n",
        "statement = \"Thank you for taking your sweet time on this!\"\n",
        "\n",
        "result = predict_sarcasm(model, statement)\n",
        "print(\"Predicted label:\", result[\"predicted_label\"])  # 0 = not sarcastic, 1 = sarcastic\n",
        "print(\"Probabilities:\", result[\"probabilities\"])"
      ],
      "metadata": {
        "id": "E4knrM6w8MsV"
      },
      "id": "E4knrM6w8MsV",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "statements = [\n",
        "    # Obvious sarcasm\n",
        "    \"Oh great, another Monday morning just what I needed!\",\n",
        "    \"I absolutely love it when my phone dies in the middle of an important call.\",\n",
        "    \"Sure, Id love to do more paperwork instead of going home early.\",\n",
        "    \"Yeah right, because traffic is exactly what I was hoping for today.\",\n",
        "    \"I totally enjoy waking up to the sound of my neighbors dog at 5 AM.\",\n",
        "\n",
        "    # Mild sarcasm\n",
        "    \"Wow, that movie was really interesting.\",\n",
        "    \"Im so glad its raining again, just perfect for a picnic.\",\n",
        "    \"Oh sure, because staying late at work is my favorite hobby.\",\n",
        "\n",
        "    # Neutral / serious\n",
        "    \"I had a sandwich for lunch.\",\n",
        "    \"The sky is blue today.\",\n",
        "    \"I am going to the grocery store after work.\",\n",
        "    \"She won the award for best performance.\"\n",
        "]\n",
        "\n",
        "statement_results = []\n",
        "results = predict_sarcasm(model, statements)\n",
        "for r, s in zip(results, statements):\n",
        "    statement_results.append({'Statement' : s, 'Is_Sarcastic' : r['predicted_label'] == 1})\n",
        "display(pd.DataFrame(statement_results))"
      ],
      "metadata": {
        "id": "x-Ec5ohi-FiC"
      },
      "id": "x-Ec5ohi-FiC",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "f863ce3b"
      },
      "source": [
        "statements_tfidf_vec = vectorizer.transform(statements)\n",
        "statements_lex_features = build_lexical_matrix(statements)\n",
        "\n",
        "statements_combined_features = hstack([statements_tfidf_vec, statements_lex_features])\n",
        "\n",
        "tfidf_predictions = clf.predict(statements_combined_features)\n",
        "\n",
        "# Create a DataFrame to display the results\n",
        "tfidf_results = []\n",
        "for s, pred in zip(statements, tfidf_predictions):\n",
        "    tfidf_results.append({'Statement': s, 'Is_Sarcastic': bool(pred)})\n",
        "\n",
        "display(pd.DataFrame(tfidf_results))"
      ],
      "id": "f863ce3b",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Seems RoBerta gets it, but TFID gets it less so, even though the prediction metrics from the testing data is not too different."
      ],
      "metadata": {
        "id": "usvaK-1PH1bk"
      },
      "id": "usvaK-1PH1bk"
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "collapsed_sections": [
        "94d2c0e8",
        "1617c189",
        "VbU7gx_1NyMa",
        "qq38meeInmJ_",
        "sZVabq22wAbj",
        "8d1ccf87",
        "8589c357",
        "26302d71"
      ],
      "gpuType": "A100",
      "provenance": [],
      "machine_shape": "hm",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.19"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}